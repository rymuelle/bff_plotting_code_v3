{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from glob import glob\n",
    "from ROOT import vector, RDataFrame, RDF, TFile, TH1F, TH2F, gInterpreter, TMath\n",
    "import ROOT\n",
    "import sys\n",
    "import yaml\n",
    "from src.RDF_tools.cpp_function import def_cpp\n",
    "from src.general.utils import toVector, get_files, prep_filelist\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "import uproot\n",
    "from pathlib import Path\n",
    "from os.path import exists\n",
    "from src.general.make_noise import beep_on_error, beep_repeat\n",
    "beep_on_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aff722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.RDF_tools.df_definitions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9463424",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-sociology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile functions in c++ for the dataframe\n",
    "def_cpp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up multithreading\n",
    "multiThreading = False\n",
    "if multiThreading: ROOT.ROOT.EnableImplicitMT()\n",
    "RDFrame = RDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0755a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'assets_feb_23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up metadata for files\n",
    "era = '2016'\n",
    "deepflavour = False\n",
    "deepcsv = True\n",
    "extras = False\n",
    "csv_v_flavor=False\n",
    "if era == \"2016\":\n",
    "    fname = \"samplesCR_2016_Apr2020.yml\"\n",
    "    bDiscValue = 0.3093\n",
    "if era == \"2017\":\n",
    "    fname = \"samplesCR_2017_Apr2020.yml\"\n",
    "    bDiscValue = 0.3033\n",
    "if era == \"2018\":\n",
    "    fname = \"samplesCR_2018_Apr2020.yml\"\n",
    "    bDiscValue = 0.2770\n",
    "\n",
    "\n",
    "sampleDir = \"samples\"\n",
    "outname = fname.replace('.yml','.root')\n",
    "fname = \"{}/{}\".format(sampleDir, fname)\n",
    "outname, fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.assets.bff_skimmer_bffv2 import *\n",
    "columns_data, columns_mc, var_postfix = make_columns(era, columns_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d22f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf266b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path ='/eos/cms/store/group/phys_exotica/bffZprime/nanoAODskimmed/crab_bffv2/{}/{{}}'.format(era)\n",
    "eff_path ='/eos/cms/store/group/phys_exotica/bffZprime/nanoAODskimmed/crab_bff_eff/{}/{{}}'.format(era)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_processor():\n",
    "    '''Class that takes file name from yml and helps manage samples.'''\n",
    "    def __init__(self,file_name,outname,bDiscValue,is_inclusive=0):\n",
    "        #load config\n",
    "        self.file_name = file_name\n",
    "        with open(file_name,'r') as f:\n",
    "            self.sample_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        #setup outfile\n",
    "        self.outname = outname\n",
    "        self.out = TFile(outname, 'recreate')\n",
    "        self.outdirs_dict = {}\n",
    "        for sample in self.samples():\n",
    "            name = sample['name']\n",
    "            self.outdirs_dict[name] = self.out.mkdir(name)\n",
    "        self.lumi = self.sample_dict['lumi']\n",
    "        #get and write lumi info\n",
    "        hlumi = TH1F(\"lumi\", \"lumi\", 1, 0, 1)\n",
    "        hlumi.SetDirectory(self.out)\n",
    "        hlumi.SetBinContent(1, self.lumi)\n",
    "        hlumi.Write()\n",
    "        self.bDiscValue = bDiscValue\n",
    "        self.is_inclusive = is_inclusive\n",
    "    def samples(self):\n",
    "        return self.sample_dict['samples']\n",
    "    def sample_names(self):\n",
    "        return [s['name'] for s in self.samples()]\n",
    "    def close(self):\n",
    "        self.out.Close()\n",
    "    def __repr__(self):\n",
    "        text_dict = {\"fn\":self.file_name,\n",
    "                     \"on\":self.outname, \n",
    "                     \"lumi\":self.lumi,\n",
    "                    \"samples\": self.sample_names()}\n",
    "        return '''from {fn} to {on}\\nlumi: {lumi}\\nSamples {samples}'''.format(**text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-television",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create instance of sample manager class \n",
    "sp = sample_processor(fname, outname, bDiscValue)\n",
    "#print(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e30ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates long list of or statements for all permuations to select for events that are present in at least one region \n",
    "rs = [\"CR10\", \"CR11\", \"CR12\", \"CR13\", \"CR14\", \"CR20\", \"CR21\", \"CR22\", \"CR23\", \"CR24\", \"SR1\", \"SR2\"]\n",
    "\n",
    "mcstring = \"\"\n",
    "for jv in var_postfix:\n",
    "    for r in rs:\n",
    "        mcstring += \"{}{} or \".format(r,jv)\n",
    "\n",
    "JERC_var = ['jet_nom_muon_corrected_pt_ele_pt']\n",
    "string = \"\"\n",
    "for jv in JERC_var:\n",
    "    for r in rs:\n",
    "        string += \"{}_{} or \".format(r,jv)\n",
    "        mcstring += \"{}_{} or \".format(r,jv)\n",
    "data_region = string[:-3]\n",
    "mc_region = mcstring[:-3]\n",
    "#mc_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99238b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sp,sample,era,verbose=1, maxEvents=1e6):\n",
    "    '''Process each sample and produced csv.'''\n",
    "    #get metadata\n",
    "    name,xsec,nEvents = sample['name'],sample['xsec'],sample['nevts']\n",
    "    ismc,dirName = int(sample['ismc']),sample['fileglob']\n",
    "    \n",
    "    # get files fit for processing\n",
    "    # filters out files that can't be opened, or are from old runs\n",
    "    # then it selects a fewer number of files to open if there are too many files\n",
    "    files_df = get_files(dirName, sample_path)\n",
    "    files, nEvents = prep_filelist(files_df, ismc, verbose=True, maxEvents=maxEvents)\n",
    "    #btageff file list\n",
    "    bTagEffGlobName = eff_path.format(dirName)\n",
    "    bTagEffGlobName = '/eos/cms/store/group/phys_exotica/bffZprime/nanoAODskimmed/crab_bff_eff/2016/DYJetsToLL_M-200to400_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8'\n",
    "    eff_paths = list(Path(bTagEffGlobName).rglob('*.root'))+ list(Path(bTagEffGlobName+\"_eff\").rglob('*.root'))\n",
    "    list_effs = list(map(lambda x: str(x), eff_paths))   \n",
    "    # get n events from skim if 0\n",
    "    sample_weight = float(xsec)*sp.lumi/float(nEvents)\n",
    " \n",
    "    if verbose: print(\"name: {} , xsec: {}, nevents: {} ismc: {}, nfiles: {}\".format(name,xsec,\n",
    "                                                                                     nEvents,ismc,\n",
    "                                                                                    len(files)))\n",
    "    #set up btagging and puid sf files\n",
    "    bTagFile, PUIDSFfile = setup_btag_puid(ismc, era, list_effs)\n",
    "    #make rdf\n",
    "    df = RDFrame('Events', files)\n",
    "    if ismc:\n",
    "        df = df.Range(0, int(maxEvents))\n",
    "    ##\n",
    "    ## filter\n",
    "    ##\n",
    "    df = df.Filter(\"DiLepMass_jet_nom_muon_corrected_pt_ele_pt>105\", \"mass_cut\")\n",
    "    if ismc:\n",
    "        df = df.Filter(mc_region, \"in_region\")\n",
    "    else:\n",
    "        df = df.Filter(data_region, \"in_region\")\n",
    "    df = df.Filter(\"Flag_METFilters==1\", \"METFilter\")    \n",
    "    ##\n",
    "    ## set up objects\n",
    "    ##    \n",
    "    var_string = '_jet_nom_muon_corrected_pt_ele_pt'\n",
    "    df = def_good_leptons(df, ismc, era, var_string)\n",
    "    ##\n",
    "    ## set weights\n",
    "    ##     \n",
    "    df = def_HLT(df, ismc, era)\n",
    "    df = bjet_weight(df,ismc, sp.is_inclusive, name, sample_weight, era)\n",
    "    df = pdf_weight(df,ismc, sp.is_inclusive, name, sample_weight, era)\n",
    "    df = fsr_isr_weight(df,ismc, sp.is_inclusive, name, sample_weight, era)\n",
    "    df = muon_weight(df,ismc, sp.is_inclusive, name, sample_weight, era)\n",
    "    df = electron_weight(df,ismc, sp.is_inclusive, name, sample_weight, era)\n",
    "    df = k_factor(df,ismc, sp.is_inclusive, name, sample_weight, era)\n",
    "    df = PU_weight(df,ismc, sp.is_inclusive, name, sample_weight, era, bDiscValue)\n",
    "    df = finalize_weights(df,ismc, sp.is_inclusive, name, sample_weight, era)\n",
    "    if ismc:\n",
    "        df = df.Define(\"JER\", \"SysPercPerObj(Jet_pt_nom, Jet_pt_jerUp, Jet_pt_jerDown, 0)\")\n",
    "        df = df.Define(\"AvgJER\", \"clip(CalcAverage(JER))\")\n",
    "        df = df.Define(\"JES\", \"SysPercPerObj(Jet_pt_nom, Jet_pt_jesTotalUp, Jet_pt_jesTotalDown, 0)\")\n",
    "        df = df.Define(\"AvgJES\", \"CalcAverage(JES)\")\n",
    "        df = df.Define(\"HEM\", \"SysPercPerObj(Jet_pt_nom, Jet_pt_jesHEMIssueUp, Jet_pt_jesHEMIssueDown, 0)\")\n",
    "        df = df.Define(\"AvgHEM\", \"CalcAverage(HEM)\")\n",
    "    else:\n",
    "        df = df.Define(\"JER\", \"1.\")\n",
    "        df = df.Define(\"AvgJER\", \"1.\")\n",
    "        df = df.Define(\"JES\", \"1.\")\n",
    "        df = df.Define(\"AvgJES\", \"1.\")\n",
    "        df = df.Define(\"HEM\", \"1.\")\n",
    "        df = df.Define(\"AvgHEM\", \"1.\")     \n",
    "    lcolumn = columns_mc\n",
    "    if not ismc:\n",
    "        lcolumn = columns_data\n",
    "    lcolumn += ['PUIDWeight','PUIDWeightUp','PUIDWeightDown',\n",
    "                'MuonTriggerEff', 'Weight_MuonTriggerUp', 'Weight_MuonTriggerDown',\n",
    "                'genWeight'\n",
    "                ,'k_factor'\n",
    "                ,'puWeight'\n",
    "                ,'PUIDWeight'\n",
    "                ,'MuonSFweight'\n",
    "                ,'ElectronSFweight'\n",
    "                ,'TriggerWeight'\n",
    "                ,'AvgMuonRecoIdIsoSFPerMuon'\n",
    "                ,'AvgMuonRocPer',\n",
    "               'AvgJER', 'AvgJES', 'AvgHEM',\n",
    "                'AvgPUIDWeightsPerJet',\n",
    "                'AvgBtagWeightCorr',\n",
    "                'AvgBtagWeightUncorr',\n",
    "               ]\n",
    "    df_np = df.AsNumpy(lcolumn)\n",
    "    df_df = pd.DataFrame(df_np)\n",
    "    df_df.to_csv('{}/data/tw_{}_{}.csv'.format(output_dir, era,name))\n",
    "    return name,df_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-consciousness",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "failed_files = []\n",
    "existing_files = []\n",
    "\n",
    "for sample in sp.samples():\n",
    "    name = sample['name']\n",
    "    maxEvents=int(2e10) if (('ZTo' in name) or ('DY' in name)) else int(1e7)\n",
    "    #if not 'Private' in name: continue\n",
    "    print(name, maxEvents)\n",
    "    if  'y3' in name: continue\n",
    "    start_time = perf_counter()\n",
    "    outname = '{}/data/tw_{}_{}.csv'.format(output_dir, era,sample['name'])\n",
    "    try:\n",
    "       \n",
    "        if not exists(outname):\n",
    "            print(\"running......\")\n",
    "            name,df = process_sample(sp,sample,era, verbose=1, maxEvents=maxEvents)\n",
    "        else:\n",
    "            print(\"exits.......\")\n",
    "            existing_files.append(outname)\n",
    "    except Exception as err:\n",
    "        failed_files.append(outname)\n",
    "        print(err)\n",
    "\n",
    "    #count = df.Count()\n",
    "    end_time = perf_counter()\n",
    "    print(\"sample {} took {:.1f} seconds\".format(name,end_time-start_time))\n",
    "\n",
    "sp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fac1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "beep_repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8101247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d490ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/tw_2017_BFFZprimeToMuMu_M_750_dbs0p04.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54278b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in df:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Weight_MuonTriggerUp.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Weight_BTagUp.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot as upr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0bdb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skim_path = '/eos/cms/store/group/phys_exotica/bffZprime/nanoAODskimmed/crab_bffv2/2017/BFF_175_dbs0p5_deepflavour_bffv2/221019_071128/0000/tree_1.root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecf503",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "upf = upr.open(skim_path)['Events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb389db5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "upf.arrays(['Muon_effSF_sys_triggerUp',\n",
    "           'Muon_effSF_trigger',\n",
    "           'Muon_effSF_sys_triggerDown'], library='pd').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tw_2016_BFFZprimeToMuMu_M_250_dbs0p04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a36992",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df.keys() if 'HLT' in x], [x for x in df.keys() if 'SR' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff049ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SR2_jet_nom_muon_corrected_pt_ele_pt.sum(), (df.SR2_jet_nom_muon_corrected_pt_ele_pt*df.HLT_Mu50).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[ \n",
    "    'MuonTriggerEff', 'Weight_MuonTriggerUp', 'Weight_MuonTriggerDown'\n",
    "    ,'AvgMuonRecoIdIsoSFPerMuon'\n",
    "                ,'AvgMuonRocPer',\n",
    "               'AvgJER', 'AvgJES', 'AvgHEM',\n",
    "                'AvgPUIDWeightsPerJet', 'AvgBtagWeight']].mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.AvgJER.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9861399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_tools.get_file_list import get_file_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb1b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "era = 2016\n",
    "file_df = get_file_df()\n",
    "file_df = file_df[file_df.era==era]\n",
    "file_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519a96d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "means_list = []\n",
    "for i, x in file_df.iterrows():\n",
    "    print(x.file)\n",
    "    _df = pd.read_csv(x.file)\n",
    "    _df = _df[_df.AvgJER<5]\n",
    "    means = _df[[ \n",
    "    'MuonTriggerEff', 'Weight_MuonTriggerUp', 'Weight_MuonTriggerDown'\n",
    "    ,'AvgMuonRecoIdIsoSFPerMuon'\n",
    "                ,'AvgMuonRocPer',\n",
    "               'AvgJER', 'AvgJES', 'AvgHEM',\n",
    "                'AvgPUIDWeightsPerJet', 'AvgBtagWeight']].mean()*100\n",
    "    means_dict = means.to_dict()\n",
    "    means_dict['mass'] = x.mass\n",
    "    means_dict['dbs'] = x.dbs\n",
    "    means_list.append(means_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame(means_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa556975",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df.min().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a22e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df.max().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df.AvgJER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a317cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
