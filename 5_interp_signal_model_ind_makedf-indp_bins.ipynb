{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd33bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.plotting_tools.Bins import bins\n",
    "from ROOT import TH1F\n",
    "import array\n",
    "import subprocess\n",
    "import uncertainties as unc\n",
    "from uncertainties import unumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ec163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plotting_tools.utils import calc_bin_widths, calc_bin_centers\n",
    "from src.plotting_tools.SysHist import SysHist\n",
    "from src.data_tools.StackPlotter import get_stack_plotter\n",
    "from src.plotting_tools.utils import rebin_np\n",
    "from src.plotting_tools.cms_format import cms_format_fig, cms_style\n",
    "from src.plotting_tools.Bins import Bins\n",
    "from src.assets.lumi import lumi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074aeb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de29d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hist(values, errors, bin_edges, *args):\n",
    "    hpx    = TH1F(*args, len(bin_edges)-1, array.array('d', bin_edges))\n",
    "    for i, (x,e) in enumerate(zip(values,errors)):\n",
    "        hpx.SetBinContent(i, x) \n",
    "        hpx.SetBinError(i, e) \n",
    "    return hpx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bdbe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_overflow(arr, top=0, bottom=0):\n",
    "    return   np.concatenate([[bottom],arr,[top]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://cms-analysis.github.io/HiggsAnalysis-CombinedLimit/part2/settinguptheanalysis/\n",
    "# https://github.com/cms-analysis/HiggsAnalysis-CombinedLimit/blob/102x/data/tutorials/shapes/simple-shapes-df_input.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.assets.output_dir import output_dir\n",
    "outdir = output_dir\n",
    "era = '2016'\n",
    "lumi_fraction = lumi_dict[str(era)]/lumi_dict['201X']\n",
    "#rootfname = '{outdir}/combine_data/{era}/{era}_shapes_df_input.root'.format(outdir=outdir, era=era)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if era=='2016':\n",
    "    lumi=1.025\n",
    "    uncorr = 1.01\n",
    "    corr_1 = 1.006\n",
    "    corr_2 = 1.0\n",
    "    lumi_str = f'''\n",
    "lumi_uncorr_{era} lnN -      {uncorr}\n",
    "lumi_corr1 lnN -      {corr_1}\n",
    "'''\n",
    "if era=='2017':\n",
    "    lumi=1.023\n",
    "    uncorr = 1.02\n",
    "    corr_1 = 1.009\n",
    "    corr_2 = 1.006\n",
    "    lumi_str = f'''\n",
    "lumi_uncorr_{era} lnN -      {uncorr}\n",
    "lumi_corr1 lnN -      {corr_1}\n",
    "lumi_corr2  lnN -      {corr_2}\n",
    "'''\n",
    "if era=='2018':\n",
    "    lumi=1.025\n",
    "    uncorr = 1.015\n",
    "    corr_1 = 1.02\n",
    "    corr_2 = 1.002\n",
    "    lumi_str = f'''\n",
    "lumi_uncorr_{era} lnN -      {uncorr}\n",
    "lumi_corr1 lnN -      {corr_1}\n",
    "lumi_corr2  lnN -      {corr_2}\n",
    "'''\n",
    "print(lumi_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = get_stack_plotter(outdir, era)\n",
    "data_dict = {}\n",
    "data_dict['SR1'] = sp.make_data_hist('DiLepMass','SR1', blinded=False)\n",
    "data_dict['SR2'] = sp.make_data_hist('DiLepMass','SR2', blinded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac15bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/data/{}_bff_interp_dbs_norm.pkl'.format(outdir, era), 'rb') as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005428bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outname=\"{}/abcd/abcd_dict_data_{}_ismc0.pkl\".format(outdir, era)\n",
    "with open(outname,'rb') as f:\n",
    "    abcd = pkl.load(f)\n",
    "    \n",
    "outname=\"{}/abcd/ABCD_closure_unc.pkl\".format(outdir, era)\n",
    "with open(outname, 'rb') as f:\n",
    "    uncertainty_dict= pkl.load(f)\n",
    "    \n",
    "    \n",
    "    print(pd.DataFrame(uncertainty_dict))\n",
    "uncertainty_dict = {k:v+1 for k,v in uncertainty_dict[int(era)].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12cede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accpt_df = pd.read_csv('/eos/cms/store/group/phys_exotica/bffZprime/assets_june_23'+\"/data_gen_b_s/summary_df.csv\")\n",
    "accpt_df\n",
    "\n",
    "isrfsr = abs((accpt_df['Weight_ISRFSR_Up']-accpt_df['Weight_ISRFSR_Down']))/(accpt_df['acceptance']*2)\n",
    "\n",
    "pdf = abs(accpt_df['Weight_PDF_Up']-accpt_df['Weight_PDF_Down'])/(accpt_df['acceptance']*2)\n",
    "\n",
    "min(isrfsr), max(isrfsr), np.mean(isrfsr), min(pdf), max(pdf), np.mean(pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''#higgs combine tool shape analysis card for z'to mumu 1 jet\n",
    "#https://github.com/cms-analysis/HiggsAnalysis-CombinedLimit/blob/102x/data/tutorials/shapes/simple-shapes-df.txt\n",
    "-------------------------\n",
    "\n",
    "imax 1  number of channels                                      #1 Jet\n",
    "jmax 1  number of backgrounds -1                                    #following AN2015_207_v5, not sure why the -1 is there?\n",
    "kmax *  number of nuisance parameters (sources of systematic uncertainties)\n",
    "\n",
    "-------------------------\n",
    "\n",
    "bin       {reg}_{era}_{binCount}\n",
    "observation   {obs}\n",
    "\n",
    "-------------------------\n",
    "\n",
    "bin       {reg}_{era}_{binCount}      {reg}_{era}_{binCount}\n",
    "process     ABCD_{reg}_{era}    sig_{reg}_{era}_{mass}_{dbs}\n",
    "process     1     -1\n",
    "rate      {abcd_count}   {sig_count}\n",
    "\n",
    "-------------------------\n",
    "back_fit_{era}_{binCount} lnN {back_fit}    -    \n",
    "Closure_{era}_{binCount} lnN  {back_closure}   -  \n",
    "jer_{era}   lnN -      {jer}\n",
    "jes_{era}   lnN -      {jes}\n",
    "roch_{era}   lnN -      {roch}\n",
    "HEM_{era}   lnN -      {HEM}\n",
    "btagCorr   lnN -      {btagCorr}\n",
    "btagUncorr_{era}   lnN -      {btagUncorr}\n",
    "elSF_{era}   lnN -      {el}\n",
    "ISRFSR_{era}   lnN -      {ISRFSR}\n",
    "Muon_{era}   lnN -      {Muon}\n",
    "trigger_{era}   lnN -      {trigger}\n",
    "pdf_{era}   lnN -      {pdf}\n",
    "puid_{era}   lnN -      {puid}\n",
    "pu   lnN -      {pu}'''\n",
    "template += lumi_str\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_bin(reg, mass, dbs, sys, nBin):\n",
    "    tdf =  data[(data.reg==reg) & (data.mass==mass) & (data.dbs==dbs) & (data.sys==sys)]\n",
    "    assert tdf.shape[0]==1, \"more than length one\"\n",
    "    row =tdf.iloc[0]\n",
    "    x, y = row.x, row.y\n",
    "    y_prime = rebin_np(x, bin_edges, y) \n",
    "    return y_prime[nBin]\n",
    "\n",
    "def get_sig_bins(reg, mass, dbs, sys, nBin, nom):\n",
    "    nom = nom+.001\n",
    "    down = get_sig_bin(reg, mass, dbs, sys.format(\"Down\"), nBin)\n",
    "    up = get_sig_bin(reg, mass, dbs, sys.format(\"Up\"), nBin)\n",
    "    x = [down/nom, up/nom]\n",
    "    if x == [0,0]: x = [1,1]\n",
    "    if (x[0]==x[1]): string = \"{:.2f}\".format(x[0])\n",
    "    else: string =  \"{:.2f}/{:.2f}\".format(*x)\n",
    "    if string == \"1.00/1.00\": string = \"1.00\"\n",
    "    return string\n",
    "\n",
    "def get_norm_bin(reg, mass, dbs, sys, norm):\n",
    "    tdf =  data[(data.reg==reg) & (data.mass==mass) & (data.dbs==dbs) & (data.sys==sys)]\n",
    "    assert tdf.shape[0]==1, \"more than length one\"\n",
    "    row =tdf.iloc[0]\n",
    "    return norm/row.y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bin_card(reg, mass, dbs, nBin, norm, stat_err, ISRFSR=\"0.97/1.03\", pdf=\"1.0\", verbose=False):\n",
    "    bin_edges = abcd[reg]['bins']\n",
    "    nom = abcd[reg]['nom'][nBin]\n",
    "    std = abcd[reg]['std'][nBin]\n",
    "    target = Bins(bin_edges).calc_bin_centers()[nBin]\n",
    "    #use new get value function to ensure matching data value\n",
    "    obs = data_dict[reg].get_value_at(target)[0]\n",
    "    if verbose: print(obs, nom)\n",
    "    #blinded\n",
    "    obs = obs\n",
    "    #signal \n",
    "    sig_nom = get_sig_bin(reg, mass, dbs, 'nom', nBin)\n",
    "    jes = get_sig_bins(reg, mass, dbs, 'Reg_jet_jesTotal{}_muon_corrected_pt_ele_pt', nBin, sig_nom)\n",
    "    roch = get_sig_bins(reg, mass, dbs, 'Reg_jet_nom_muon_corrected{}_pt_ele_pt', nBin, sig_nom)\n",
    "    jer = get_sig_bins(reg, mass, dbs, 'Reg_jet_jer{}_muon_corrected_pt_ele_pt', nBin, sig_nom)\n",
    "    pu = get_sig_bins(reg, mass, dbs, 'Weight_Pu{}', nBin, sig_nom)\n",
    "    btagCorr = get_sig_bins(reg, mass, dbs, 'Weight_BTagCorr{}', nBin, sig_nom)\n",
    "    btagUncorr = get_sig_bins(reg, mass, dbs, 'Weight_BTagUncorr{}', nBin, sig_nom)\n",
    "    puid = get_sig_bins(reg, mass, dbs, 'Weight_PUID{}', nBin, sig_nom)\n",
    "    #pdf = get_sig_bins(reg, mass, dbs, 'Weight_PDF_{}', nBin, sig_nom)\\\n",
    "    pdf = pdf\n",
    "    #fixed 2% width\n",
    "    ISRFSR  = ISRFSR #= get_sig_bins(reg, mass, dbs, 'Weight_ISRFSR_{}', nBin, sig_nom)\n",
    "    muon = get_sig_bins(reg, mass, dbs, 'Weight_MuonSF{}', nBin, sig_nom)\n",
    "    el = get_sig_bins(reg, mass, dbs, 'Weight_ElectronSF{}', nBin, sig_nom)\n",
    "    trigger = get_sig_bins(reg, mass, dbs, 'Weight_MuonTrigger{}', nBin, sig_nom)\n",
    "    try:\n",
    "        HEM = get_sig_bins(reg, mass, dbs, \"Reg_jet_jesHEMIssue{}_muon_corrected_pt_ele_pt\", nBin, sig_nom)\n",
    "    except:\n",
    "        HEM = \"1.00\"\n",
    "        \n",
    "    #scale sig_nom \n",
    "    norm_factor = get_norm_bin(reg, mass, dbs, 'nom', norm)\n",
    "    sig_nom = sig_nom*norm_factor\n",
    "    \n",
    "    value_dict = {\n",
    "                \"era\": era,\n",
    "                \"reg\": reg,\n",
    "                \"binCount\": nBin,\n",
    "                \"lumi\": lumi, \n",
    "                \"mass\": mass, \n",
    "                \"dbs\": dbs,\n",
    "                \"obs\": \"{:.2f}\".format(obs),\n",
    "        \n",
    "                \"abcd_count\": \"{:.2f}\".format(nom),\n",
    "                \"back_fit\": \"{:.2f}\".format((nom+std)/nom),\n",
    "                \"back_closure\": \"{:.2f}\".format(uncertainty_dict[reg]),\n",
    "        \n",
    "                \"sig_count\": \"{:.2f}\".format(sig_nom),\n",
    "                \"jer\": jer,\n",
    "                \"jes\": jes,\n",
    "                \"roch\": roch,\n",
    "                \"HEM\": HEM,\n",
    "                \"btagCorr\": btagCorr,\n",
    "                \"btagUncorr\": btagUncorr,\n",
    "                \"el\": el,\n",
    "                \"ISRFSR\": ISRFSR,\n",
    "                \"Muon\": muon,\n",
    "                \"trigger\": trigger,\n",
    "                \"pdf\": pdf,\n",
    "                \"puid\": puid,\n",
    "                \"pu\": pu,\n",
    "                \"stat\": \"{:.2f}\".format(1+stat_err/norm),\n",
    "                 }\n",
    "    return template.format(**value_dict), sig_nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e90ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/afs/cern.ch/work/r/rymuelle/public/nanoAODzPrime/CMSSW_12_1_0/src/bff_plotting_code_v3/exo-datacards/EXO-22-006/combine_data/model_ind'\n",
    "path = '{}/combine_data/model_ind'.format(outdir)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c16938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ddefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mass.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers = calc_bin_centers(abcd['SR1']['bins'])\n",
    "reg, mass, dbs, fs_type = 'SR1', 250, 0.04, '1b'\n",
    "bin_edges = abcd[reg]['bins']\n",
    "\n",
    "def make_card(reg, mass, dbs, fs_type):\n",
    "    combine_str = 'combineCards.py '\n",
    "    \n",
    "    signal = '{}_{}_{}_{}'.format(reg, mass, str(dbs).replace('.', 'p'), fs_type.replace('(','-').replace(')','-'))\n",
    "    path_prime = '{}/{}/{}'.format(path, era, signal)\n",
    "\n",
    "    acceptance_row = accpt_df[(accpt_df.reg==reg) & (accpt_df.mass==mass) & (accpt_df.type==fs_type)]\n",
    "    assert acceptance_row.shape[0] == 1, acceptance_row\n",
    "    acceptance = acceptance_row.iloc[0]['acceptance']\n",
    "    stat_error = acceptance_row.iloc[0]['statistical']\n",
    "    norm = acceptance*1000*lumi_fraction\n",
    "    isrfsr = get_sys(acceptance_row.iloc[0], \"Weight_ISRFSR\")\n",
    "    pdf = get_sys(acceptance_row.iloc[0], \"Weight_PDF\")\n",
    "    print(isrfsr, pdf)\n",
    "    os.makedirs(path_prime, exist_ok=True)\n",
    "    for i in range(len(bin_centers)):\n",
    "        # don't count 0 sig bins for speed\n",
    "        sig_count = get_sig_bin(reg, mass, dbs, 'nom', i)\n",
    "        if sig_count==0: continue\n",
    "        template_filled, sig_nom = make_bin_card(reg, mass, dbs, i, norm, stat_error, ISRFSR=isrfsr, pdf=pdf)\n",
    "        with open('{}/bin_{}.txt'.format(path_prime, i), 'w') as f:\n",
    "            f.write(template_filled)\n",
    "            combine_str+= ' Name{}={}/bin_{}.txt'.format(i,signal, i)\n",
    "    combine_str += ' > datacard_{}.txt\\n'.format(signal)\n",
    "    return combine_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd3e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_sys(row, string):\n",
    "    syses = sorted([1+row[string+\"_Up\"]/row['acceptance'], 1+row[string+\"_Down\"]/row['acceptance']])\n",
    "\n",
    "    syses_string = [\"{:.2f}\".format(sys) for sys in syses]\n",
    "    if syses_string[0]==\"1.00\" and syses_string[1]==\"1.00\": syses_string=\"1.00\"\n",
    "    else: syses_string = \"{}/{}\".format(*syses_string)\n",
    "    return syses_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1890a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combine_sh = '#!bin/bash\\n'\n",
    "dbs = 0.5\n",
    "for fs_type in accpt_df.type.unique():\n",
    "    for mass in [125, 150, 175, 200, 250, 300, 350]:\n",
    "        print(fs_type, mass)\n",
    "        for reg in ['SR1', 'SR2']:\n",
    "            #print(fs_type, mass, reg)\n",
    "            combine_sh += make_card(reg, mass, dbs, fs_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57cd346",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/{}/make_combine.sh'.format(path, era), 'w') as f:\n",
    "    f.write(combine_sh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979cc88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for fs_type in accpt_df.type.unique():\n",
    "    for mass in [125, 150, 175, 200, 250, 300, 350]:\n",
    "        combine_sh_all_years ='combineCards.py '\n",
    "        i = 0\n",
    "        for era in [2016, 2017, 2018]:\n",
    "            for reg in ['SR1', 'SR2']:\n",
    "                combine_sh_all_years += \" Name{i}={era}/datacard_{reg}_{mass}_0p5_{fs_type}.txt\".format(i=i, era=era, reg=reg,mass=mass, \n",
    "                                                                                                        fs_type=fs_type.replace('(','-').replace(')','-'))\n",
    "                i+=1\n",
    "        combine_sh_all_years += ' > 201X/datacard_{}_0p5_{}.txt'.format(mass, fs_type.replace('(','-').replace(')','-'))\n",
    "        print(combine_sh_all_years)\n",
    "    \n",
    "for fs_type in accpt_df.type.unique():\n",
    "    for mass in [125, 150, 175, 200, 250, 300, 350]:\n",
    "        combine_sh_all_years ='combineCards.py '\n",
    "        i = 0\n",
    "        for era in [2016, 2017, 2018]:\n",
    "            for reg in ['SR1']:\n",
    "                combine_sh_all_years += \" Name{i}={era}/datacard_{reg}_{mass}_0p5_{fs_type}.txt\".format(i=i, era=era, reg=reg,mass=mass, \n",
    "                                                                                                        fs_type=fs_type.replace('(','-').replace(')','-'))\n",
    "                i+=1\n",
    "        combine_sh_all_years += ' > 201X/datacard_SR1_{}_0p5_{}.txt'.format(mass, fs_type.replace('(','-').replace(')','-'))\n",
    "        print(combine_sh_all_years)\n",
    "    \n",
    "for fs_type in accpt_df.type.unique():\n",
    "    for mass in [125, 150, 175, 200, 250, 300, 350]:\n",
    "        combine_sh_all_years ='combineCards.py '\n",
    "        i = 0\n",
    "        for era in [2016, 2017, 2018]:\n",
    "            for reg in ['SR2']:\n",
    "                combine_sh_all_years += \" Name{i}={era}/datacard_{reg}_{mass}_0p5_{fs_type}.txt\".format(i=i, era=era, reg=reg,mass=mass, \n",
    "                                                                                                        fs_type=fs_type.replace('(','-').replace(')','-'))\n",
    "                i+=1\n",
    "        combine_sh_all_years += ' > 201X/datacard_SR2_{}_0p5_{}.txt'.format(mass, fs_type.replace('(','-').replace(')','-'))\n",
    "        print(combine_sh_all_years)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881f4c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# era combine regions\n",
    "for fs_type in accpt_df.type.unique():\n",
    "    fs_string = fs_type.replace('(','-').replace(')','-')\n",
    "    for dbs in [0.5]:\n",
    "        dbsstring = str(dbs).replace('.', 'p')\n",
    "        for mass in [125, 150, 175, 200, 250, 300, 350]:\n",
    "            for era in [2016, 2017, 2018]:\n",
    "                combine_sh ='combineCards.py '\n",
    "                i = 0\n",
    "                for reg in ['SR1', 'SR2']:\n",
    "                    combine_sh += f\" Name{i}={era}/datacard_{reg}_{mass}_0p5_{fs_string}.txt\"\n",
    "                    i+=1\n",
    "                combine_sh += f' > {era}/datacard_{mass}_0p5_{fs_string}.txt'\n",
    "                print(combine_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440773b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_combine = '''#!/bin/sh\n",
    "#ulimit -s unlimited\n",
    "#set -e\n",
    "cd /afs/cern.ch/work/r/rymuelle/public/nanoAODzPrime/higgscombine/CMSSW_10_2_13/src\n",
    "export SCRAM_ARCH=slc7_amd64_gcc700\n",
    "source /cvmfs/cms.cern.ch/cmsset_default.sh\n",
    "eval `scramv1 runtime -sh`\n",
    "cd {path} \n",
    "\n",
    "combine -M AsymptoticLimits \"$1\"\n",
    "\n",
    "'''.format(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8420ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cp src/combine_scripts/* {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ded883",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/run_combine.sh'.format(path), 'w') as f:\n",
    "    f.write(run_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375285f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {path}/out\n",
    "!mkdir {path}/err\n",
    "!mkdir {path}/log\n",
    "\n",
    "!mkdir {path}/out/2016\n",
    "!mkdir {path}/err/2016\n",
    "!mkdir {path}/log/2016\n",
    "\n",
    "!mkdir {path}/out/2017\n",
    "!mkdir {path}/err/2017\n",
    "!mkdir {path}/log/2017\n",
    "\n",
    "\n",
    "!mkdir {path}/out/2018\n",
    "!mkdir {path}/err/2018\n",
    "!mkdir {path}/log/2018\n",
    "\n",
    "\n",
    "!mkdir {path}/out/201X\n",
    "!mkdir {path}/err/201X\n",
    "!mkdir {path}/log/201X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "condor_submit submit_jobs_201X.sub\n",
    "condor_submit submit_jobs_2016.sub\n",
    "condor_submit submit_jobs_2017.sub\n",
    "condor_submit submit_jobs_2018.sub\n",
    "watch condor_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d6a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481361d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bff_12_1",
   "language": "python",
   "name": "bff_12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
