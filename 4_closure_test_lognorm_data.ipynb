{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#surpress divide warnings\n",
    "np.errstate(invalid='ignore', divide='ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from src.data_tools.get_data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a433950",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plotting_tools.draw_stack_plot_hists import draw_bckground, draw_signals, draw_data, draw_stackplot\n",
    "from src.plotting_tools.SysHist import SysHist\n",
    "from src.plotting_tools.Bins import Bins, bins\n",
    "from src.plotting_tools.utils import ratio_plot_template\n",
    "from src.data_tools.StackPlotter import get_stack_plotter\n",
    "from src.plotting_tools.latexAssets import mll\n",
    "from src.assets.output_dir import output_dir\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_bins = bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed905cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.general.array_utils import moving_average, moving_sum, super_sample, super_sample_function, moving_avg_func, unp_array_to_nom_std\n",
    "from src.plotting_tools.cms_format import cms_style, cms_format_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from src.general.functions import power_func, power_law, make_bpoly, linear, parabola, make_bpoly_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from src.general.functions import make_bpoly, lognorm, log_norm_np, log_norm_unp\n",
    "from src.plotting_tools.SysHist import SysHist\n",
    "import uncertainties\n",
    "import uncertainties.unumpy as unp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c434fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16860067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = 'assets_feb_23'\n",
    "outdir = '{}/abcd'.format(output_dir)\n",
    "era = '2016'\n",
    "ismc=0\n",
    "isdata = ismc==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = get_stack_plotter(output_dir, era, bins='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78836174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_hists(fhist, dhist, ismc_pull = False, n=10, ndof=0, log=1, flabel=\"\", dlabel=\"\", \n",
    "                  dhist_isdata=0, fhist_is_data=0, ratio=False,  isabcd=0, **kwargs):\n",
    "    fcolor = 'green' if isabcd else 'blue'\n",
    "    \n",
    "    fig, ax, rax = ratio_plot_template(figsize=(10,10))\n",
    "    #top plots\n",
    "    fhist.draw(ax, label=flabel, zorder=3,color=fcolor)\n",
    "    if dhist_isdata:\n",
    "        ax.errorbar(dhist.calc_bin_centers(), dhist.nominal, yerr=dhist.std, color='black', label=dlabel, ls='', marker='o', zorder=3)\n",
    "    else:\n",
    "        dhist.draw(ax, label=dlabel, zorder=1, errorbar=False, draw_sys=0, color='red', alpha=0)#, sys_label='Background Systematics')\n",
    "    x = fhist.calc_bin_centers()\n",
    "    \n",
    "    #calc pull\n",
    "    nom1_avg = moving_sum(fhist.nominal, n = n)\n",
    "    nom2_avg = moving_sum(dhist.nominal, n = n)\n",
    "    var1_avg = moving_sum(fhist.std**2, n = n)\n",
    "    var2_avg = moving_sum(dhist.std**2, n = n)\n",
    "    x_avg = moving_average(x, n=n)\n",
    "    if ismc_pull:\n",
    "        pull = (nom1_avg-nom2_avg)/(var2_avg+var1_avg)**.5\n",
    "    else:\n",
    "        pull = (nom1_avg-nom2_avg)/nom1_avg**.5\n",
    "    pullsquare = pull**2\n",
    "    \n",
    "    if ratio:\n",
    "        rax.plot(x, np.full(len(x), .5) , color='black', linestyle=':')\n",
    "        rax.plot(x, np.full(len(x), 0) , color='black')\n",
    "        rax.plot(x, np.full(len(x), 1.5) , color='black', linestyle=':') \n",
    "\n",
    "        if isabcd:\n",
    "            fhist.calc_ratio(fhist.nominal).draw(rax, zorder=1, color=fcolor)\n",
    "        else:\n",
    "            fhist.calc_ratio(fhist.nominal).draw(rax, zorder=1)\n",
    "        if dhist_isdata:\n",
    "            rdhist = dhist.calc_ratio(fhist.nominal)\n",
    "            rax.errorbar(rdhist.calc_bin_centers(), rdhist.nominal, yerr=rdhist.std, color='black', label=dlabel, ls='', marker='o', zorder=3)\n",
    "        else:\n",
    "            dhist.calc_ratio(fhist.nominal).draw(rax, label=dlabel, zorder=0, errorbar=False, color='red', alpha=0.5)\n",
    "            #dhist.calc_ratio(fhist.nominal).draw(rax, zorder=0, errorbar=False)\n",
    "    else:\n",
    "        rax.plot(x, np.full(len(x), 1) , color='black', linestyle=':')\n",
    "        rax.plot(x, np.full(len(x), 0) , color='black')\n",
    "        rax.plot(x, np.full(len(x), -1) , color='black', linestyle=':')\n",
    "        rax.plot(x_avg, pull)\n",
    "    \n",
    "    #format ax\n",
    "    if isdata:\n",
    "        cms_format_fig(era, ax, \"\\emph{Preliminary}\")\n",
    "    else:\n",
    "        cms_format_fig(era, ax, \"\\emph{Simulation}\")\n",
    "    if log:\n",
    "        ax.set_yscale('Log')\n",
    "            \n",
    "    ax.set_ylabel('Counts per GeV')\n",
    "    \n",
    "    #format rax\n",
    "    rax.set_ylim(0,2)\n",
    "    if ratio:\n",
    "        if dhist_isdata:\n",
    "            rax.set_ylabel('Obs./Fit')\n",
    "            if isabcd: rax.set_ylabel('Obs./ABCD')\n",
    "        else:\n",
    "            if isabcd: rax.set_ylabel('MC/ABCD')\n",
    "            else: rax.set_ylabel('MC/Fit')\n",
    "    else:\n",
    "        rax.set_ylim(-5,5)\n",
    "        rax.set_ylabel('Pull')\n",
    "        \n",
    "    rax.set_xlabel('{} [GeV]'.format(mll))\n",
    "    return  {'chi2': (pullsquare).sum()/(fhist.calc_nBins()-ndof),\n",
    "             'fig': fig,\n",
    "             'ax': ax,\n",
    "             'rax': rax}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_hist(func, hist, n=10, comp_hist_n =10, do_super_sample=1, ismc=False,  do_unc=1, color='red', \n",
    "             flabel=\"\", dlabel=\"\", dhist_isdata=0, fhist_is_data=0, **kwargs):\n",
    "    x = np.array(hist.calc_bin_centers())\n",
    "    if not isdata:\n",
    "        popt, pcov = curve_fit(func, x, hist.nominal, \n",
    "                       **kwargs,\n",
    "                       sigma=hist.std, maxfev = int(1e6))  \n",
    "    else:\n",
    "        #std is not optimal for data: zero and low count bins will be subotimal error estimates\n",
    "        popt, pcov = curve_fit(func, x, hist.nominal, \n",
    "               **kwargs, maxfev = int(1e6))  \n",
    "    if do_unc:\n",
    "        #create fit values with uncertainties\n",
    "        popt_unc = uncertainties.correlated_values(popt, pcov)\n",
    "        #make_fit_hist\n",
    "        y = log_norm_unp(x, *popt_unc)\n",
    "        y_nom, y_std = unp_array_to_nom_std(y)\n",
    "    else: \n",
    "        y_nom = func(x, *popt)\n",
    "        varper = ((hist.nominal-y_nom)**2/y_nom).mean()\n",
    "        y_std = (varper*y_nom)**.5\n",
    "        y_std = y_nom**.5\n",
    "    fit_hist = SysHist(\n",
    "            y_nom,\n",
    "            x*0, x*0, \n",
    "            y_std,\n",
    "            np.array(hist.bin_edges)\n",
    "        ).normalize().calc_ratio(1/hist.calc_sum())\n",
    "\n",
    "    compare_dict = compare_hists(fit_hist, hist, ismc=ismc, n=comp_hist_n, color = color, ndof=5, flabel=flabel, dlabel=dlabel, dhist_isdata=dhist_isdata)\n",
    "    \n",
    "    return {**compare_dict, \n",
    "            \"popt\" : np.array(popt),\n",
    "            \"pcov\": np.array(pcov),\n",
    "            \"fit_hist\": fit_hist\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_value = 120\n",
    "top_value=405\n",
    "feature='DiLepMass'\n",
    "sp.x_range = (bottom_value, top_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23516dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1704a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp_hist_n = 1\n",
    "sp.rebin = 0\n",
    "fit_dict = {}\n",
    "for reg in ['CR14','CR24', 'CR10','CR20', 'CR13', 'CR23']:\n",
    "    #data for fitting, data or MC?\n",
    "    if isdata:\n",
    "        _plot_dict = sp.make_data_hist(feature, reg)\n",
    "    else:\n",
    "        _plot_dict = sp.combine_back(feature, reg)\n",
    "    #reduce the range for fitting\n",
    "    hist = _plot_dict.reduce_range(bottom=bottom_value, top=top_value)\n",
    "    if ismc: hist.std += gaussian_filter(hist.std,2)\n",
    "    #hist.up *=0\n",
    "    #hist.down *=0\n",
    "    total_events = hist.nominal.sum()\n",
    "    #fit the hist\n",
    "    flabel='Observed Fit' if isdata else 'MC Fit'\n",
    "    dlabel = 'Observed' if isdata else None\n",
    "    # fit and pull plot\n",
    "    \n",
    "    \n",
    "    curve_fit_chi2 = fit_hist(log_norm_np, hist, comp_hist_n=comp_hist_n, do_super_sample=0, \n",
    "                              ismc=ismc, p0=[total_events*10, .8, 80, 70], \n",
    "                              bounds = ([0, .2, 50, 50], [total_events*100, 1, 100, 100]),\n",
    "                              do_unc=1, flabel=flabel, dlabel=dlabel, dhist_isdata=isdata,fhist_is_data=isdata,\n",
    "                             )\n",
    "    \n",
    "    \n",
    "    sp.draw_background(curve_fit_chi2['ax'], feature, reg, sys_label='Stat. + Sys.', errorbar=False)\n",
    "    print(reg)\n",
    "    fit_dict[reg] = curve_fit_chi2\n",
    "    print(reg, curve_fit_chi2['chi2'],  repr(curve_fit_chi2['popt']))\n",
    "    # reorder legend\n",
    "    handles, labels = curve_fit_chi2['ax'].get_legend_handles_labels()\n",
    "    order = [0,1,2,3,4,5,7,6]\n",
    "    if ismc: order = np.linspace(0,len(handles)-1, len(handles), dtype=int)\n",
    "    curve_fit_chi2['ax'].legend([handles[idx] for idx in order],[labels[idx] for idx in order], \n",
    "                                ncol=2)\n",
    "    curve_fit_chi2['ax'].set_ylim(bottom=1e0, top=1e4)\n",
    "    curve_fit_chi2['fig'].savefig('{}/fit_data_pull_era{}_ismc{}_reg{}_bottom{}_lognorm.pdf'.format(outdir,era,ismc,reg,bottom_value))\n",
    "    plt.show()\n",
    "    #200gev pull\n",
    "    curve_fit_chi2['ax'].set_xlim(left=bottom_value, right=200)\n",
    "    curve_fit_chi2['rax'].set_xlim(left=bottom_value, right=200)\n",
    "    curve_fit_chi2['fig'].savefig('{}/fit_data_pull_era{}_ismc{}_reg{}_bottom{}_lognorm_200GeVMax.pdf'.format(outdir,era,ismc,reg,bottom_value))\n",
    "\n",
    "    ### ratio plot\n",
    "    #rebin to split binning for these plots\n",
    "    sp.rebin = 0 #split_bins.bin_edges\n",
    "    bhist = sp.combine_back(feature, reg).make_density_hist()\n",
    "    bhist.nominal += 1e-10\n",
    "    fit_hist_rebin = curve_fit_chi2['fit_hist'].reduce_range(bottom=bottom_value, top=top_value).make_density_hist()\n",
    "    ratio_dict = compare_hists(fit_hist_rebin, bhist, n=comp_hist_n, \n",
    "                               color = 'red', ndof=5, flabel=flabel, ratio=True, dhist_isdata=0, fhist_is_data=isdata)\n",
    "    ratio_dict['ax'].legend()\n",
    "    sp.draw_background(ratio_dict['ax'], feature, reg, sys_label='Stat. + Sys.', errorbar=False)\n",
    "    if isdata:\n",
    "        data_plot = sp.make_data_hist(feature, reg).make_density_hist()\n",
    "        ratio_dict['ax'].errorbar(data_plot.calc_bin_centers(), data_plot.nominal, yerr=data_plot.std, \n",
    "                    color='black', label='Observed', ls='', marker='o', zorder=2)\n",
    "        \n",
    "        ratio_dict['rax'].errorbar(data_plot.calc_bin_centers(), data_plot.nominal/bhist.nominal,\n",
    "                                   yerr=data_plot.std/bhist.nominal, \n",
    "                    color='black', ls='', marker='o', zorder=.5)        \n",
    "        \n",
    "    handles, labels = ratio_dict['ax'].get_legend_handles_labels()\n",
    "    order = [0,1,2,3,4,6,5,7]\n",
    "    if ismc: order = np.linspace(0,len(handles)-1, len(handles), dtype=int)\n",
    "    ratio_dict['ax'].legend([handles[idx] for idx in order],[labels[idx] for idx in order], \n",
    "                                ncol=2)\n",
    "\n",
    "    ratio_dict['ax'].set_ylim(bottom=1e0, top=1e4)\n",
    "    ratio_dict['fig'].savefig('{}/fit_mc_ratio_era{}_ismc{}_reg{}_bottom{}_lognorm.pdf'.format(outdir,era,ismc,reg,bottom_value))\n",
    "    plt.show()\n",
    "    #200gev pull\n",
    "    ratio_dict['ax'].set_xlim(left=bottom_value, right=200)\n",
    "    ratio_dict['rax'].set_xlim(left=bottom_value, right=200)\n",
    "    ratio_dict['fig'].savefig('{}/fit_mc_ratio_era{}_ismc{}_reg{}_bottom{}_lognorm_200GeVMax.pdf'.format(outdir,era,ismc,reg,bottom_value))\n",
    "    sp.rebin = 0\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### abcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fit_hist(template_hist, reg):\n",
    "    tmp_xrange = sp.x_range\n",
    "    sp.x_range = (-np.inf, np.inf)\n",
    "    template_hist = sp.combine_back(feature, reg)\n",
    "    x = np.array(template_hist.calc_bin_centers())\n",
    "    popt, pcov = fit_dict[reg]['popt'], fit_dict[reg]['pcov']\n",
    "    popt_unc = uncertainties.correlated_values(popt, pcov)\n",
    "    y = log_norm_unp(x, *popt_unc)\n",
    "    y_nom, y_std = unp_array_to_nom_std(y)\n",
    "    fit_hist = SysHist(\n",
    "            y_nom,\n",
    "            x*0, x*0, \n",
    "            y_std,\n",
    "            np.array(template_hist.bin_edges)\n",
    "        )\n",
    "    sp.x_range = tmp_xrange\n",
    "    return fit_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_abcd(nJets):\n",
    "    from copy import deepcopy\n",
    "    A = deepcopy(make_fit_hist(bhist, 'CR{}0'.format(nJets)))\n",
    "    B = deepcopy(make_fit_hist(bhist, 'CR{}3'.format(nJets)))\n",
    "    C = deepcopy(make_fit_hist(bhist, 'CR{}4'.format(nJets)))\n",
    "    abcd = A.uncertainty_std_dev()*B.uncertainty_std_dev()/C.uncertainty_std_dev()\n",
    "    print( A.uncertainty_std_dev().sum(), B.uncertainty_std_dev().sum(), C.uncertainty_std_dev().sum(), abcd.sum())\n",
    "    abcd_nom, abcd_std = unp_array_to_nom_std(abcd)\n",
    "    return SysHist(abcd_nom, abcd_nom*0,abcd_nom*0,abcd_std, A.bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72306d19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#abcd plots\n",
    "for nJets in [1,2]:\n",
    "    reg = 'SR{}'.format(nJets)\n",
    "    #make abcd hist\n",
    "    abcd_hist = make_abcd(nJets)\n",
    "    abcd_hist = abcd_hist.rebin(split_bins.bin_edges).reduce_range(bottom=bottom_value, top=top_value)\n",
    "    #background hist\n",
    "    sp.rebin = split_bins.bin_edges\n",
    "    bhist = sp.combine_back(feature, reg)\n",
    "    #data hist\n",
    "    dhist = sp.make_data_hist(feature, reg, blinded=False)\n",
    "\n",
    "    #ratio\n",
    "    flabel = 'Obs. ABCD' if isdata else 'MC ABCD'\n",
    "    ratio_dict = compare_hists(abcd_hist.make_density_hist(), dhist.make_density_hist(), isdata=1, n=comp_hist_n, \n",
    "                                   color = 'red', ndof=5, flabel=flabel, ratio=True, dhist_isdata=1, isabcd=1)\n",
    "\n",
    "    sp.draw_background(ratio_dict['ax'], feature, reg, sys_label='Stat. + Sys.', errorbar=False)\n",
    "    #sp.draw_data(ratio_dict['ax'], feature, reg)\n",
    "    \n",
    "    handles, labels = ratio_dict['ax'].get_legend_handles_labels()\n",
    "    order = [0,1,2,3,4,6,5]\n",
    "    if ismc: order = np.linspace(0,len(handles)-1, len(handles), dtype=int)\n",
    "    ratio_dict['ax'].legend([handles[idx] for idx in order],[labels[idx] for idx in order], \n",
    "                                ncol=2)\n",
    "    \n",
    "    ratio_dict['ax'].set_ylim(bottom=1e0, top=1e3)\n",
    "    ratio_dict['fig'].savefig('{}/abcd_mc_ratio_era{}_ismc{}_regSR{}_bottom{}_lognorm_splt_binning.pdf'.format(outdir,era,ismc,nJets,bottom_value))\n",
    "    #200 GeV zoom in \n",
    "    ratio_dict['ax'].set_xlim(left=bottom_value, right=200)\n",
    "    ratio_dict['rax'].set_xlim(left=bottom_value, right=200)\n",
    "    ratio_dict['fig'].savefig('{}/abcd_mc_ratio_era{}_ismc{}_regSR{}_bottom{}_lognorm_splt_binning_200GeVMax.pdf'.format(outdir,era,ismc,nJets,bottom_value))\n",
    "    \n",
    "    #pull\n",
    "    pull_dict = compare_hists(abcd_hist.make_density_hist(), dhist.make_density_hist(), isdata=1, n=comp_hist_n, \n",
    "                                   color = 'red', ndof=5, flabel=flabel, ratio=False, dhist_isdata=1, isabcd=1)\n",
    "    sp.draw_background(pull_dict['ax'], feature, reg, sys_label='Stat. + Sys.', errorbar=False)\n",
    "    handles, labels = pull_dict['ax'].get_legend_handles_labels()\n",
    "    order = [0,1,2,3,4,6,5]\n",
    "    if ismc: order = np.linspace(0,len(handles)-1, len(handles), dtype=int)\n",
    "    pull_dict['ax'].legend([handles[idx] for idx in order],[labels[idx] for idx in order], \n",
    "                                ncol=2)\n",
    "    pull_dict['ax'].set_ylim(bottom=1e0, top=1e3)\n",
    "    pull_dict['fig'].savefig('{}/abcd_mc_pull_era{}_ismc{}_regSR{}_bottom{}_lognorm_splt_binning.pdf'.format(outdir,era,ismc,nJets,bottom_value))\n",
    "    #200 GeV zoom in \n",
    "    pull_dict['ax'].set_xlim(left=bottom_value, right=200)\n",
    "    pull_dict['rax'].set_xlim(left=bottom_value, right=200)\n",
    "    pull_dict['fig'].savefig('{}/abcd_mc_pull_era{}_ismc{}_regSR{}_bottom{}_lognorm_splt_binning_200GeVMax.pdf'.format(outdir,era,ismc,nJets,bottom_value))\n",
    "    sp.rebin = 0\n",
    "\n",
    "    #save data\n",
    "    fit_dict['SR{}'.format(nJets)]= ratio_dict\n",
    "    fit_dict['SR{}'.format(nJets)]['fit_hist'] = abcd_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6dfd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer factor plot\n",
    "def make_TF(nJets):\n",
    "    A = make_fit_hist(bhist, 'CR{}0'.format(nJets)).rebin(split_bins.bin_edges)\n",
    "    B = make_fit_hist(bhist, 'CR{}3'.format(nJets)).rebin(split_bins.bin_edges)\n",
    "    C = make_fit_hist(bhist, 'CR{}4'.format(nJets)).rebin(split_bins.bin_edges)\n",
    "    tf = A.uncertainty_std_dev()/C.uncertainty_std_dev()\n",
    "    \n",
    "    tf_nom, tf_std = unp_array_to_nom_std(tf)\n",
    "    return SysHist(tf_nom, tf_nom*0,tf_nom*0,tf_std, A.bin_edges)\n",
    "tf_dict = {}\n",
    "#abcd plots\n",
    "for nJets in [1,2]:\n",
    "    reg = 'SR{}'.format(nJets)\n",
    "    #make abcd hist\n",
    "    tf_hist = make_TF(nJets)\n",
    "    tf_hist = tf_hist.reduce_range(bottom=bottom_value, top=top_value)\n",
    "    fig, ax = plt.subplots()\n",
    "    A = make_fit_hist(bhist, 'CR{}0'.format(nJets))\n",
    "    B = make_fit_hist(bhist, 'CR{}3'.format(nJets))\n",
    "    C = make_fit_hist(bhist, 'CR{}4'.format(nJets))\n",
    "    #A.calc_ratio(C.nominal).draw(ax)\n",
    "    tf_hist.draw(ax)\n",
    "    #C.draw(ax)\n",
    "    #tf_hist.draw(ax)\n",
    "    tf_dict[nJets] = tf_hist.to_dict()\n",
    "    \n",
    "import pickle as pkl\n",
    "with open('{}/tf_dict_{}_ismc{}.pkl'.format(outdir, era, ismc), 'wb') as f:\n",
    "    pkl.dump(tf_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ae407",
   "metadata": {},
   "outputs": [],
   "source": [
    "{reg: item['chi2'] for reg, item in fit_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be752fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_list = []\n",
    "for reg, item in fit_dict.items():\n",
    "    if isdata:\n",
    "        _plot_dict = sp.make_data_hist(feature, reg).reduce_range(bottom=bottom_value, top=top_value)\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "        _plot_dict = sp.draw_background(ax, feature, reg).reduce_range(bottom=bottom_value, top=top_value)\n",
    "    _fit_dict = {\n",
    "        \"era\": era,\n",
    "        \"region\": reg,\n",
    "    'n_{background}': \"{:.2f}\".format(_plot_dict.uncertainty_std_dev().sum()),\n",
    "    'n_{ABCD,Data}': \"{:.2f}\".format(item['fit_hist'].uncertainty_std_dev().sum()),\n",
    "    ' Data $\\chi^2/n_{DOF}$': \"{:.2f}\".format(item['chi2'])\n",
    "    }\n",
    "    if not 'SR' in reg:\n",
    "        popt_unc = uncertainties.correlated_values(item['popt'], item['pcov'])\n",
    "        param_names = inspect.getfullargspec(log_norm_np).args[1:]\n",
    "        treg_dict = {**{n:\"{:.2f}\".format(u) for u, n in zip(popt_unc, param_names) }}\n",
    "        _fit_dict = {**_fit_dict, **treg_dict}    \n",
    "    fit_list.append(_fit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d3a0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('{}/fit_stats_data_{}_ismc{}.txt'.format(outdir,era, ismc), 'w') as f:\n",
    "    latex = pd.DataFrame(fit_list)[['era', 'region', 'n_{background}',  'n_{ABCD,Data}', 'sigma', 'theta', 'mean',\n",
    "       ' Data $\\chi^2/n_{DOF}$']].to_latex(index=False)\n",
    "    print(latex)\n",
    "    f.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19969bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame(fit_list)[['era', 'region', 'n_{background}',  'sigma', 'theta', 'mean', 'n_{ABCD,Data}',\n",
    "       ' Data $\\chi^2/n_{DOF}$']]\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17993d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "40665*5778.39/28601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format dict for saving\n",
    "limit_dict = {}\n",
    "for reg, item in fit_dict.items():\n",
    "    limit_dict[reg] = item['fit_hist'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a66dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('{}/abcd_dict_data_{}_ismc{}.pkl'.format(outdir, era, ismc), 'wb') as f:\n",
    "    pkl.dump(limit_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_dict_skimmed = {}\n",
    "for k, v in fit_dict.items():\n",
    "    v = {k2:v2 for k2,v2 in v.items() if not k2 in ['fig', 'ax','rax']}\n",
    "    fit_dict_skimmed[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867811b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('{}/fit_dict_data_{}_ismc{}.pkl'.format(outdir, era, ismc), 'wb') as f:\n",
    "    pkl.dump(fit_dict_skimmed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f241af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'{}/abcd_dict_data_{}_ismc{}.pkl'.format(outdir, era, ismc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b14e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## sample from covariance\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13eca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480920d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 'CR10'\n",
    "popt = fit_dict[reg]['popt']\n",
    "pcov = fit_dict[reg]['pcov']\n",
    "popt_unc = uncertainties.correlated_values(popt, pcov)\n",
    "\n",
    "pcov, popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf491716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3702fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_norm_unp_safe(*args):\n",
    "    try:\n",
    "        return log_norm_unp(*args)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def make_hists_region(reg, n_random = 10):\n",
    "    popt = fit_dict[reg]['popt']\n",
    "    pcov = fit_dict[reg]['pcov']\n",
    "    popt_unc = uncertainties.correlated_values(popt, pcov)\n",
    "    nvars = len(popt)\n",
    "    # covariance matrix version\n",
    "    _x = np.array(split_bins.calc_bin_centers())\n",
    "    _x = np.linspace(120,400, 100)\n",
    "    \n",
    "    _y = log_norm_unp(_x, *popt_unc)\n",
    "    _y_nom, _y_std = unp_array_to_nom_std(_y)\n",
    "    \n",
    "    #\"square root\" of covariance matrix\n",
    "    w, v = np.linalg.eig(pcov)\n",
    "    sigma = np.sqrt(w) * v\n",
    "    #print(np.linalg.cholesky(pcov))\n",
    "    \n",
    "    #do extras so we can drop invalid params\n",
    "    random_popts = np.random.default_rng().multivariate_normal(popt, pcov, n_random)\n",
    "    \n",
    "    y_randoms = np.apply_along_axis(lambda p: abs(log_norm_unp_safe(_x, *p)), 1, random_popts)\n",
    "    y_randoms = [y for y in y_randoms if not type(y)==int]\n",
    "    #cut down to length\n",
    "    y_randoms = y_randoms[:n_random]\n",
    "    #implied mc uncertainties:\n",
    "    array = np.stack(y_randoms).astype('float')\n",
    "    mc_unc = array.std(axis=0)\n",
    "    mc_unc\n",
    "\n",
    "    return {\"y\": _y, \"y_nom\": _y_nom, \"y_std\": _y_std, \"x\": _x, \"random_popts\": random_popts, \"y_randoms\": np.array(y_randoms).astype('float'), \"popt_unc\": popt_unc, 'pcov': pcov, 'mc_unc': mc_unc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a030c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_norm_unp_safe(*args):\n",
    "    try:\n",
    "        return log_norm_unp(*args)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def make_hists_region(reg, n_random = 10):\n",
    "    popt = fit_dict[reg]['popt']\n",
    "    pcov = fit_dict[reg]['pcov']\n",
    "    popt_unc = uncertainties.correlated_values(popt, pcov)\n",
    "    nvars = len(popt)\n",
    "    # covariance matrix version\n",
    "    _x = np.array(split_bins.calc_bin_centers())\n",
    "    _x = np.linspace(120,400, 100)\n",
    "    \n",
    "    _y = log_norm_unp(_x, *popt_unc)\n",
    "    _y_nom, _y_std = unp_array_to_nom_std(_y)\n",
    "    \n",
    "    #\"square root\" of covariance matrix\n",
    "    w, v = np.linalg.eig(pcov)\n",
    "    sigma = np.sqrt(w) * v\n",
    "    #print(np.linalg.cholesky(pcov))\n",
    "    \n",
    "    #do extras so we can drop invalid params\n",
    "    random_popts = (sigma @ np.random.randn(nvars, int(n_random*1.5))).T + popt\n",
    "    #random_popts = np.matmul(np.random.rand(n_random, nvars),np.linalg.cholesky(pcov))+popt\n",
    "    \n",
    "    y_randoms = list(map(lambda p: abs(log_norm_unp_safe(_x, *p)), random_popts))\n",
    "    y_randoms = [y for y in y_randoms if not type(y)==int]\n",
    "    #cut down to length\n",
    "    y_randoms = y_randoms[:n_random]\n",
    "    #implied mc uncertainties:\n",
    "    array = np.stack(y_randoms).astype('float')\n",
    "    mc_unc = array.std(axis=0)\n",
    "\n",
    "    return {\"y\": _y, \"y_nom\": _y_nom, \"y_std\": _y_std, \"x\": _x, \"random_popts\": random_popts, \"y_randoms\": np.array(y_randoms).astype('float'), \"popt_unc\": popt_unc, 'pcov': pcov, 'mc_unc': mc_unc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2bab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hists_region(reg, n_random = 10):\n",
    "    popt = fit_dict[reg]['popt']\n",
    "    pcov = fit_dict[reg]['pcov']\n",
    "    popt_unc = uncertainties.correlated_values(popt, pcov)\n",
    "    nvars = len(popt)\n",
    "    # covariance matrix version\n",
    "    _x = np.array(split_bins.calc_bin_centers())\n",
    "    _x = np.linspace(120,400, 100)\n",
    "    \n",
    "    _y = log_norm_unp(_x, *popt_unc)\n",
    "    _y_nom, _y_std = unp_array_to_nom_std(_y)\n",
    "    \n",
    "    #\"square root\" of covariance matrix\n",
    "    w, v = np.linalg.eig(pcov)\n",
    "    sigma = np.sqrt(w) * v\n",
    "    #print(np.linalg.cholesky(pcov))\n",
    "    \n",
    "    #do extras so we can drop invalid params\n",
    "    # https://stats.stackexchange.com/questions/120179/generating-data-with-a-given-sample-covariance-matrix\n",
    "    random_popts = np.random.default_rng().multivariate_normal(popt, pcov, n_random).T\n",
    "    means = (random_popts.mean(axis=1)).reshape(-1,1)\n",
    "    mean_subtracted = random_popts - means\n",
    "    \n",
    "    # Make each variable in X orthogonal to one another\n",
    "    L_inv = np.linalg.cholesky(np.cov(mean_subtracted, bias = True))\n",
    "    L_inv = np.linalg.inv(L_inv)\n",
    "    mean_subtracted = np.dot(L_inv, mean_subtracted)\n",
    "    \n",
    "    # Rescale X to exactly match Sigma\n",
    "    L = np.linalg.cholesky(pcov)\n",
    "    mean_subtracted = np.dot(L, mean_subtracted)\n",
    "    print(\"delta covariance matrix: \", pcov, \"\\n\",  np.cov(mean_subtracted))\n",
    "    #add means back in\n",
    "    random_popts = mean_subtracted + means\n",
    "    #rotate it back\n",
    "    random_popts = random_popts.T\n",
    "\n",
    "    y_randoms = np.apply_along_axis(lambda p: abs(log_norm_unp_safe(_x, *p)), 1, random_popts)\n",
    "    y_randoms = [y for y in y_randoms if not sum(y)==0]\n",
    "    #cut down to length\n",
    "    y_randoms = y_randoms[:n_random]\n",
    "    #implied mc uncertainties:\n",
    "    array = np.stack(y_randoms).astype('float')\n",
    "    mc_unc = array.std(axis=0)\n",
    "    mc_unc\n",
    "\n",
    "    return {\"y\": _y, \"y_nom\": _y_nom, \"y_std\": _y_std, \"x\": _x, \"random_popts\": random_popts, \"y_randoms\": np.array(y_randoms).astype('float'), \"popt_unc\": popt_unc, 'pcov': pcov, 'mc_unc': mc_unc}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0dbf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " make_hists_region(\"CR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def make_cov_plots(cov_dict, region):\n",
    "    length = len(cov_dict['y_randoms'])\n",
    "    \n",
    "    #plot fit information\n",
    "    fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "    \n",
    "    #mc fits\n",
    "    ax.errorbar([0,1], [0,1], color='red', zorder=0, label='MC fit variations')\n",
    "    for i, y in enumerate(cov_dict['y_randoms']): \n",
    "        ax.errorbar(cov_dict['x'],  y/cov_dict['y_nom'], alpha=20/length, color='red', zorder=0)\n",
    "    \n",
    "    #covariance fit\n",
    "    ax.errorbar(cov_dict['x'], cov_dict['y_nom']/cov_dict['y_nom'], yerr=cov_dict['y_std']/cov_dict['y_nom'], zorder=2, label='From covariance')\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_xlim(110,400)\n",
    "    ax.set_ylim(.5, 1.5)\n",
    "    cms_format_fig(era, ax, \"\\emph{Preliminary}\")\n",
    "    ax.set_xlabel('$m_{\\ell\\ell}$ [GeV]')\n",
    "    ax.set_ylabel('$f(x)_{var.}/f(x)_{nom.}$')\n",
    "    fig.savefig(f'{outdir}/fit_corr_MC_fits_{era}_{ismc}_{region}.pdf')\n",
    "    \n",
    "    #implied error\n",
    "    fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "    ax.plot(cov_dict['x'], cov_dict['y_std']/cov_dict['y_nom'], label='Std. Dev. from Cov. Matrix')\n",
    "    ax.plot(cov_dict['x'], cov_dict['mc_unc']/cov_dict['y_nom'], label='Std. Dev. from MC',  color='red')\n",
    "    ax.set_xlim(110,400)\n",
    "    ax.set_ylim(0,.3)\n",
    "    ax.legend()\n",
    "    ax.set_ylabel('(Per Bin Uncertainty)/Nominal')\n",
    "    ax.set_xlabel('$m_{\\ell\\ell}$ [GeV]')\n",
    "    cms_format_fig(era, ax, \"\\emph{Preliminary}\")\n",
    "    fig.savefig(f'{outdir}/fit_corr_implied_error_{era}_{ismc}_{region}.pdf')\n",
    "    \n",
    "    #correlation plot\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,12))\n",
    "    \n",
    "    corrcoef = np.corrcoef(cov_dict['y_randoms'].T)\n",
    "    \n",
    "    df_corrcoef = pd.DataFrame(corrcoef, index = cov_dict['x'].round(),\n",
    "                  columns = cov_dict['x'].round())\n",
    "\n",
    "    sns.heatmap(df_corrcoef, annot=False,\n",
    "               vmin=-1, vmax=1, center=0,\n",
    "        cmap=sns.diverging_palette(20, 220, n=200),\n",
    "        square=True)\n",
    "    \n",
    "    #ticks = np.linspace(120, 400, int((400-120)/10+1), dtype='int')\n",
    "    #ax.set_xticklabels(ticks)\n",
    "    #ax.set_yticklabels(ticks)\n",
    "    ax.set_xlabel('$m_{\\ell\\ell}$ [GeV]')\n",
    "    ax.set_ylabel('$m_{\\ell\\ell}$ [GeV]')\n",
    "    cms_format_fig(era, ax, \"\\emph{Preliminary}\")\n",
    "    fig.savefig(f'{outdir}/fit_corr_corrplot_{era}_{ismc}_{region}.pdf')\n",
    "    \n",
    "    #envelope plot\n",
    "    \n",
    "    fig, ax = plt.subplots( figsize=(12,12))\n",
    "    cov_dict_randoms_sorted = sorted(cov_dict['y_randoms'], key=lambda x: x[0])\n",
    "    \n",
    "    #bottom 300\n",
    "    for i, y in enumerate(cov_dict_randoms_sorted[int(length*(1-.165)): int(length*(1-.155))]): \n",
    "        ax.errorbar(cov_dict['x'],  y/cov_dict['y_nom'], alpha=20/length, color='red', zorder=0)\n",
    "            \n",
    "    for i, y in enumerate(cov_dict_randoms_sorted[int(length*(.155)): int(length*(.165))]): \n",
    "        ax.errorbar(cov_dict['x'],  y/cov_dict['y_nom'], alpha=20/length, color='blue', zorder=0)\n",
    "        \n",
    "    \n",
    "    up = np.array(cov_dict_randoms_sorted[int(length*(1-.165)): int(length*(1-.155))]).mean(axis=0)\n",
    "    down = np.array(cov_dict_randoms_sorted[int(length*(.155)): int(length*(.165))]).mean(axis=0)\n",
    "    \n",
    "    \n",
    "    ax.errorbar(pdictB['x'],  up/cov_dict['y_nom'], color='blue', zorder=0, label='approx 68\\% env up')\n",
    "    ax.errorbar(pdictB['x'],  down/cov_dict['y_nom'],  color='red', zorder=0, label='approx 68\\% env down')\n",
    "    \n",
    "    ax.set_ylabel('$f(x)_{var.}/f(x)_{nom.}$')\n",
    "    ax.set_xlabel('$m_{\\ell\\ell}$ [GeV]')\n",
    "    ax.errorbar(cov_dict['x'], cov_dict['y_nom']/cov_dict['y_nom'], yerr=cov_dict['y_std']/cov_dict['y_nom'], zorder=2, label='From covariance')\n",
    "    cms_format_fig(era, ax, \"\\emph{Preliminary}\")\n",
    "    ax.set_xlim(110,400)\n",
    "    ax.set_ylim(.5, 1.5)\n",
    "    ax.legend()\n",
    "    fig.savefig(f'{outdir}/fit_corr_envplot_{era}_{ismc}_{region}.pdf')\n",
    "    \n",
    "    #fig.savefig('{outdir}/fit_corr_'.format(outdir,era,ismc,nJets,bottom_value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79818e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10000\n",
    "pdictB = make_hists_region('CR10', n_random=length)\n",
    "\n",
    "pdictC = make_hists_region('CR13', n_random=length)\n",
    "\n",
    "pdictD = make_hists_region('CR14', n_random=length)\n",
    "ABCD_randoms = (pdictB['y_randoms']*pdictC['y_randoms']/pdictD['y_randoms'])\n",
    "ABCD_unc = ABCD_randoms.std(axis=0)\n",
    "ABCD = pdictB['y']*pdictC['y']/pdictD['y']\n",
    "ABCD_nom, ABCD_std = unp_array_to_nom_std(ABCD)   \n",
    "\n",
    "ABCD_dict = {\"y\": ABCD, \"y_nom\": ABCD_nom, \"y_std\": ABCD_std, \"x\": pdictD['x'], \"y_randoms\": ABCD_randoms, \"mc_unc\":ABCD_unc }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15488543",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6709955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_cov_plots(ABCD_dict, \"SR1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c322658",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_cov_plots(pdictB, \"CR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c0009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_cov_plots(pdictC, \"CR13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbe62f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_cov_plots(pdictD, \"CR14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1000\n",
    "pdictB = make_hists_region('CR20', n_random=length)\n",
    "pdictC = make_hists_region('CR23', n_random=length)\n",
    "pdictD = make_hists_region('CR24', n_random=length)\n",
    "ABCD_randoms = (pdictB['y_randoms']*pdictC['y_randoms']/pdictD['y_randoms'])\n",
    "ABCD_unc = ABCD_randoms.std(axis=0)\n",
    "ABCD = pdictB['y']*pdictC['y']/pdictD['y']\n",
    "ABCD_nom, ABCD_std = unp_array_to_nom_std(ABCD)   \n",
    "\n",
    "ABCD_dict = {\"y\": ABCD, \"y_nom\": ABCD_nom, \"y_std\": ABCD_std, \"x\": pdictD['x'], \"y_randoms\": ABCD_randoms, \"mc_unc\":ABCD_unc }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdf4f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_cov_plots(ABCD_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23c228",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_cov_plots(pdictB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "pdictB = make_hists_region('CR10', n_random=length)\n",
    "pdictB.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d2f1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# note that the stddev of the random pops is the same as teh stdev from the uncertainty \n",
    "pdictB['popt_unc'][0], pdictB['random_popts'][:,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b675e237",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now, lets sort popts and y_randoms by the first value:\n",
    "def sort_by_index(i):\n",
    "    return np.stack(sorted(pdictB['random_popts'], key=lambda x:x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b51ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "poptsorted = sort_by_index(index)\n",
    "log_norm_unp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcce8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def select_envelope(_poptsorted, _index, _envelope=.68):\n",
    "#     mean, stdev = _poptsorted[:,0].mean(), _poptsorted[:,0].std()\n",
    "#     up = _poptsorted[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, stdev = poptsorted[:,index].mean(), poptsorted[:,index].std()\n",
    "mean, stdev\n",
    "plt.hist(poptsorted[:,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7691882",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "x = pdictB['x']\n",
    "for ls, i in zip([':', \"-.\", \"--\"], [.33, .66, 1]):\n",
    "    sigma =  i\n",
    "    epsilon = .01\n",
    "    up_top, up_bottom = mean+stdev*(sigma+epsilon), mean+stdev*(sigma-epsilon) \n",
    "    up_pop = poptsorted[(poptsorted[:,index] < up_top) & (poptsorted[:,index] > up_bottom)]\n",
    "    \n",
    "    down_top, down_bottom = mean-stdev*(sigma+epsilon), mean-stdev*(sigma-epsilon) \n",
    "    down_pop = poptsorted[(poptsorted[:,index] < down_bottom) & (poptsorted[:,index] > down_top)]\n",
    "    \n",
    "    x = pdictB['x']\n",
    "    y_random_up = np.apply_along_axis(lambda p: abs(log_norm_unp_safe(x, *p)), 1, up_pop)\n",
    "    y_random_up = np.stack([y for y in y_random_up if not type(y)==int])\n",
    "    \n",
    "    y_random_down = np.apply_along_axis(lambda p: abs(log_norm_unp_safe(x, *p)), 1, down_pop)\n",
    "    y_random_down = np.stack([y for y in y_random_down if not type(y)==int])\n",
    "    \n",
    "    y_down = y_random_down.mean(axis=0)\n",
    "    y_up = y_random_up.mean(axis=0)\n",
    "    y_up.sum(), y_down.sum(), pdictB['y_nom'].sum()\n",
    "    y_down = y_down/y_down.sum()*pdictB['y_nom'].sum()\n",
    "    y_up = y_up/y_up.sum()*pdictB['y_nom'].sum()\n",
    "    \n",
    "    _ = ax.plot(x, y_down.T/pdictB['y_nom'], label='down {} $\\sigma$'.format(i), color='red', ls=ls)\n",
    "    _ = ax.plot(x, y_up.T/pdictB['y_nom'], label='up {} $\\sigma$'.format(i), color='green', ls=ls)\n",
    "    \n",
    "    \n",
    "_ = ax.errorbar(x, pdictB['y_nom']/pdictB['y_nom'], yerr=pdictB['y_std']/pdictB['y_nom'])\n",
    "ax.legend(ncol=3)\n",
    "\n",
    "cms_format_fig(era, ax, '\\emph{Preliminary}')\n",
    "ax.set_ylabel('Ratio with Nominal')\n",
    "ax.set_xlabel('$m_{\\ell\\ell}$ [GeV]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e639879",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_randoms_sum = sorted(pdictB['y_randoms'], key=lambda x: sum(x))\n",
    "\n",
    "foo = lambda x: x[-1]\n",
    "foo = lambda x: x[-1]-x[0]/47\n",
    "sums = np.array(list(map(foo, pdictB['y_randoms'])))\n",
    "mean, std = np.mean(sums), np.std(sums)\n",
    "mean, std\n",
    "plt.hist(sums, bins=np.linspace(mean-5*std, mean+5*std, 100))\n",
    "\n",
    "def get_slice(arr, value, width, foo):\n",
    "    x = np.array(list(map(foo, arr)))\n",
    "    print(value*(1-width), value*(1+width))\n",
    "    xrange = sorted((value*(1-width), value*(1+width)))\n",
    "    return arr[(x > xrange[0]) &  (x < xrange[1])]\n",
    "\n",
    "\n",
    "up_slice = get_slice(pdictB['y_randoms'], mean+std, .01, foo)\n",
    "down_slice = get_slice(pdictB['y_randoms'], mean-std, .01, foo)\n",
    "\n",
    "y_down = down_slice.mean(axis=0)\n",
    "y_up = up_slice.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d53691",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_up.sum(), y_down.sum(), pdictB['y_nom'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cce999",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(y_down.T/pdictB['y_nom'])\n",
    "_ = plt.plot(y_up.T/pdictB['y_nom'])\n",
    "_ = plt.plot(pdictB['y_nom']/pdictB['y_nom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075cf09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bff_12_1",
   "language": "python",
   "name": "bff_12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
