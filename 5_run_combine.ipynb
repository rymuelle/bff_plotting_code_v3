{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob\n",
    "import re\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file_df(pattern='201[0-9].*txt'):\n",
    "    '''This function produces a dataframe of all the cfg files that we could run combine over.'''\n",
    "    file_list = [f for f in glob.glob('combine_data/*') if len(re.findall(pattern,f)) > 0]\n",
    "    cfg_list =[]\n",
    "    for i, f in enumerate(file_list):\n",
    "        nJets = re.findall(r'SR.', f)[0]\n",
    "        mass = (re.findall(r'M_(\\d+)_', f)[0])\n",
    "        sig_type = (re.findall(r'Mu_([a-z]+)_M_', f)[0])\n",
    "        dbs = re.findall(r'dbs(\\d)p(\\d+)', f)[0]\n",
    "        dbs = ('{}.{}'.format(*dbs))\n",
    "        era = (re.findall(r'(201.)',f)[0])\n",
    "        cfg_list.append({\"file\":f, \"nJets\":nJets, \"mass\":mass, \"dbs\":dbs, \"era\": era, \"sig_type\": sig_type})\n",
    "    return pd.DataFrame(cfg_list)\n",
    "   \n",
    "def make_combine_df(_df, _name):\n",
    "    '''This function takes a dataframe of configs and produces a single datacard with those cards.'''\n",
    "    files = _df.file.to_numpy()\n",
    "    file_string = \"combineCards.py\"\n",
    "    for count, f in enumerate(files):\n",
    "        file_string += \" name{}={}\".format(count, f)\n",
    "    p = subprocess.Popen(file_string.split(' '), stdout=subprocess.PIPE, \n",
    "                                   stderr=subprocess.PIPE)\n",
    "    out, err = p.communicate()\n",
    "    with open(_name, 'wb') as f:\n",
    "        f.write(out)\n",
    "\n",
    "df = make_file_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting some params for which era and stuff to run on\n",
    "era = '2016'\n",
    "run_hist_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_template = 'combine_data/{}_{}_BFFZprimeToMuMu_{}_M_{}_dbs{}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For this year, produce SR1 and SR2 combined cards. New retion is called SRX\n",
    "mass_dbs_nJets = df[['mass', 'dbs', 'nJets', 'sig_type']].to_numpy().astype(str)\n",
    "for (mass, dbs, _, sig_type) in np.unique(mass_dbs_nJets, axis=0):\n",
    "    #select for era, dbs, mass, sig type (fit or hist)\n",
    "    df_temp = df[(df.era==era) & (df.dbs==dbs) & (df.mass==mass)  & (df.sig_type==sig_type) & (df.nJets!=\"SRX\")]\n",
    "    #make combined config\n",
    "    fname = filename_template.format(era, 'SRX', sig_type, mass, str(dbs).replace('.', 'p'))\n",
    "    make_combine_df(df_temp, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Produce combined limits for a mass, dbs point for all eras.\n",
    "mass_dbs_nJets = df[['mass', 'dbs', 'nJets', 'sig_type']].to_numpy().astype(str)\n",
    "for (mass, dbs, _, sig_type) in np.unique(mass_dbs_nJets, axis=0):\n",
    "    df_temp = df[(df.dbs==dbs) & (df.mass==mass)  & (df.sig_type==sig_type) & (df.nJets!=\"SRX\")]\n",
    "    # three years, two regions. If something is wrong, do not run to avoid confusion\n",
    "    if df_temp.shape[0] != 3*2: continue\n",
    "    fname = filename_template.format(\"201X\", 'SRX', sig_type, mass, str(dbs).replace('.', 'p'))\n",
    "    make_combine_df(df_temp, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all files, including new created ones\n",
    "df = make_file_df(pattern='201.*txt')\n",
    "\n",
    "df = df[df.era==era]\n",
    "#remove signals that are marked hist type, these are for testing purposes only\n",
    "if not run_hist_test: df = df[df.sig_type==\"fit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compute limits\n",
    "# We do this using subprocess to run a command line command. Is there a python api?\n",
    "#This is the command to run, change it as needed\n",
    "combine_command_template = \"combine -M AsymptoticLimits {} --run blind\"\n",
    "#This will save the results\n",
    "limit_list = []\n",
    "for i, (f, mass, dbs, nJets, era, sig_type) in enumerate(df[['file', 'mass', 'dbs', 'nJets', 'era', 'sig_type']].to_numpy()):\n",
    "    print(f, mass, dbs, nJets, era)\n",
    "    command = combine_command_template.format(f)\n",
    "    print(command)\n",
    "    print('file: {}, {} out of {}'.format(f, i, df.shape[0]))\n",
    "    p = subprocess.Popen(command.split(' '), stdout=subprocess.PIPE, \n",
    "                                   stderr=subprocess.PIPE)\n",
    "    out, err = p.communicate()\n",
    "    print(command)\n",
    "    print(out.decode('utf-8')) \n",
    "    #find and save results\n",
    "    limits = re.findall(r'Expected +(\\d+.\\d+)%: r < (\\d+.\\d+)',out.decode('UTF-8'))\n",
    "    lim_dict = {k:float(v) for k,v in limits}\n",
    "    lim_dict['mass'] = int(mass)\n",
    "    lim_dict['nJets'] = (nJets)\n",
    "    lim_dict['dbs'] = float(dbs)\n",
    "    lim_dict['era'] = era\n",
    "    lim_dict['sig_type'] = sig_type\n",
    "    limit_list.append(lim_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df = pd.DataFrame(limit_list)\n",
    "lim_df = lim_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lim_df.sort_values(['mass', 'dbs'])[(lim_df.sig_type=='fit') & (lim_df.nJets=='SR2') ][['mass','dbs', '16.0', '50.0', '84.0']].round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lim_df.sort_values(['mass', 'dbs'])[(lim_df.sig_type=='hist') & (lim_df.nJets=='SR2') ][['mass','dbs', '16.0', '50.0', '84.0']].round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df.to_csv('limits/limit_{}.csv'.format(era))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
